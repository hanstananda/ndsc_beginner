{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras.engine import Layer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Conv1D, GlobalMaxPooling1D, Flatten, LSTM, \\\n",
    "    Bidirectional, CuDNNLSTM, MaxPooling1D, ConvLSTM2D, CuDNNGRU, SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from utility.train_data_loader import load_train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_embeddings_index():\n",
    "    embeddings_index = {}\n",
    "    for line in glove_file:\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-300])\n",
    "        coefs = np.asarray(values[-300:], dtype='float32')\n",
    "        # print(coefs)\n",
    "        embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"using glove data from joblib...\")\n",
    "    embeddings_index = joblib.load(\"../data/glove.840B.300d.joblib\")\n",
    "    print(\"glove data loaded from joblib!\")\n",
    "except:\n",
    "    print(\"using glove data from txt...\")\n",
    "    glove_file = open('../data/glove.840B.300d.txt', \"r\", encoding=\"Latin-1\")\n",
    "    embeddings_index = update_embeddings_index()\n",
    "    print(\"glove data loaded from txt!\")\n",
    "    joblib.dump(embeddings_index, \"../data/glove.840B.300d.joblib\")\n",
    "    print(\"glove data saved to joblib!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"../data/new_test.csv\")\n",
    "dictData = pd.read_csv(\"../data/kata_dasar_kbbi.csv\")\n",
    "categories_file = open(\"../data/categories.json\", \"r\")\n",
    "trainData = load_train_data()\n",
    "\n",
    "# Shuffle train data\n",
    "trainData = shuffle(trainData)\n",
    "\n",
    "categories = json.load(categories_file)\n",
    "inverted_categories_mobile = {v: k.lower() for k, v in categories['Mobile'].items()}\n",
    "inverted_categories_fashion = {v: k.lower() for k, v in categories['Fashion'].items()}\n",
    "inverted_categories_beauty = {v: k.lower() for k, v in categories['Beauty'].items()}\n",
    "\n",
    "all_subcategories = {k.lower(): v for k, v in categories['Mobile'].items()}\n",
    "all_subcategories.update({k.lower(): v for k, v in categories['Fashion'].items()})\n",
    "all_subcategories.update({k.lower(): v for k, v in categories['Beauty'].items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main settings\n",
    "plot_history_check = True\n",
    "gen_test = False\n",
    "max_length = 35  # 32 is max word in train\n",
    "max_words = 2500\n",
    "EMBEDDING_DIM = 300  # Based on the txt file: glove 300d\n",
    "num_classes = len(all_subcategories)\n",
    "# Training for more epochs will likelval-acc after 10 epochs: 0.71306y lead to overfitting on this dataset\n",
    "# You can try tweaking these hyperparamaters when using this model with your own data\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "print(all_subcategories)\n",
    "print(\"no of categories: \" + str(num_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_data_size = int(len(trainData) * 1)\n",
    "train_data_size = int(max_data_size * .95)\n",
    "train_data_step = 1\n",
    "validate_data_step = 1\n",
    "print(train_data_size, max_data_size)\n",
    "\n",
    "train_texts = trainData['title'][::train_data_step]\n",
    "train_tags = trainData['Category'][::train_data_step]\n",
    "test_texts = testData['title']\n",
    "print(len(train_texts), len(train_tags))\n",
    "\n",
    "\n",
    "\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_texts)  # only fit on train\n",
    "x_train = tokenize.texts_to_sequences(train_texts)\n",
    "x_test = tokenize.texts_to_sequences(test_texts)\n",
    "\n",
    "# Pad sequences with zeros\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=max_length)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=max_length)\n",
    "\n",
    "y_train = train_tags.values\n",
    "y_train = utils.to_categorical(y_train)\n",
    "word_index = tokenize.word_index\n",
    "\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
