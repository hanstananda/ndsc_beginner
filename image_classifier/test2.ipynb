{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Conv1D, GlobalMaxPooling1D, Bidirectional, CuDNNLSTM, \\\n",
    "    SpatialDropout1D, MaxPooling1D,Conv2D,MaxPooling2D,Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utility.train_data_loader import load_train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 256\n",
    "specialization = \"fashion\"\n",
    "gen_test = True\n",
    "\n",
    "categories_file = open(\"../data/categories.json\", \"r\")\n",
    "categories = json.load(categories_file)\n",
    "\n",
    "all_subcategories = {k.lower(): v for k, v in categories['Mobile'].items()}\n",
    "all_subcategories.update({k.lower(): v for k, v in categories['Fashion'].items()})\n",
    "all_subcategories.update({k.lower(): v for k, v in categories['Beauty'].items()})\n",
    "\n",
    "data_root = \"../../\"+specialization+\"_image/\"\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08,rescale=1./255)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08,rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08,rescale=1./255)\n",
    "\n",
    "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\"\n",
    "\n",
    "trainData = load_train_data()\n",
    "testData = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "validation_data_specialized = trainData[trainData['image_path'].str.contains(specialization)][::100]\n",
    "validation_data_specialized['image_path'] = validation_data_specialized['image_path']. \\\n",
    "    map(lambda x: x.replace(specialization + '_image/', ''))\n",
    "\n",
    "test_data_specialized = testData[testData['image_path'].str.contains(specialization)]\n",
    "test_data_specialized['image_path'] = test_data_specialized['image_path'].\\\n",
    "    map(lambda x: x.replace(specialization+'_image/', ''))\n",
    "\n",
    "inverted_categories_specialized = {k.lower(): v for k, v in categories[specialization.capitalize()].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503 167\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "2000 200\n",
      "1296 144\n"
     ]
    }
   ],
   "source": [
    "train_data_specialized = trainData[trainData['image_path'].str.contains(specialization)][::]\n",
    "df_train = pd.DataFrame()\n",
    "df_valid = pd.DataFrame()\n",
    "num_train=2000\n",
    "num_valid=int(0.1*num_train)\n",
    "for k,v in inverted_categories_specialized.items():\n",
    "    rows = train_data_specialized.loc[train_data_specialized['Category'] == v]\n",
    "    num_images = rows.shape[0]\n",
    "    if(num_train+num_valid>num_images):\n",
    "        nt=int(0.9*num_images)\n",
    "        nv=int(0.1*num_images)\n",
    "    else:\n",
    "        nt=num_train\n",
    "        nv=num_valid\n",
    "    # print(nt,nv)\n",
    "    rows_train = rows[:nt]\n",
    "    df_train = df_train.append(rows_train)\n",
    "    rows_valid = rows[nt:(nt+num_valid)]\n",
    "    df_valid = df_valid.append(rows_valid)\n",
    "\n",
    "train_data_specialized = df_train\n",
    "validation_data_specialized = df_valid\n",
    "\n",
    "train_data_specialized['image_path'] = train_data_specialized['image_path']. \\\n",
    "    map(lambda x: x.replace(specialization + '_image/', ''))\n",
    "\n",
    "validation_data_specialized['image_path'] = validation_data_specialized['image_path']. \\\n",
    "    map(lambda x: x.replace(specialization + '_image/', ''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26799 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))\n",
    "image_generator = datagen.flow_from_dataframe(train_data_specialized,\n",
    "                                              directory=os.path.join(data_root),\n",
    "                                              x_col=\"image_path\",\n",
    "                                              y_col=\"item_category\",\n",
    "                                              target_size=IMAGE_SIZE,\n",
    "                                              color_mode=\"grayscale\",\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              shuffle=True,\n",
    "                                              batch_size=64,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape:  (64, 224, 224, 1)\n",
      "Label batch shape:  (64, 14)\n"
     ]
    }
   ],
   "source": [
    "label_names = sorted(image_generator.class_indices.items(), key=lambda pair:pair[1])\n",
    "label_names = np.array([key.title() for key, value in label_names])\n",
    "\n",
    "\n",
    "def feature_extractor(x):\n",
    "    feature_extractor_module = hub.Module(feature_extractor_url)\n",
    "    return feature_extractor_module(x)\n",
    "\n",
    "\n",
    "for image_batch, label_batch in image_generator:\n",
    "    print(\"Image batch shape: \", image_batch.shape)\n",
    "    print(\"Label batch shape: \", label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 222, 222, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 394272)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               50466944  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 50,469,070\n",
      "Trainable params: 50,469,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = IMAGE_SIZE+[1] \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(inverted_categories_specialized), activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2713 images belonging to 14 classes.\n",
      "Found 55440 images.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = valid_datagen.flow_from_dataframe(validation_data_specialized,\n",
    "                                                    directory=os.path.join(data_root),\n",
    "                                                    x_col=\"image_path\",\n",
    "                                                    y_col=\"item_category\",\n",
    "                                                    target_size=IMAGE_SIZE,\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle=True,\n",
    "                                                    batch_size=64,\n",
    "                                                    )\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(test_data_specialized,\n",
    "                                                  directory=os.path.join(data_root),\n",
    "                                                  x_col=\"image_path\",\n",
    "                                                  y_col=None,\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  color_mode=\"grayscale\",\n",
    "                                                  class_mode=None,\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=64,\n",
    "                                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55440, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_specialized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "418/418 [==============================] - 152s 364ms/step - loss: 6.0101 - acc: 0.0931 - val_loss: 2.5871 - val_acc: 0.1443\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.14435, saving model to ../checkpoints/epoch_10_03_19_2019_00_40_06v2.hdf5\n",
      "Epoch 2/10\n",
      "418/418 [==============================] - 153s 365ms/step - loss: 2.4338 - acc: 0.2067 - val_loss: 2.4517 - val_acc: 0.1854\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.14435 to 0.18535, saving model to ../checkpoints/epoch_10_03_19_2019_00_40_06v2.hdf5\n",
      "Epoch 3/10\n",
      "418/418 [==============================] - 155s 370ms/step - loss: 1.9293 - acc: 0.3885 - val_loss: 2.4253 - val_acc: 0.1986\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.18535 to 0.19857, saving model to ../checkpoints/epoch_10_03_19_2019_00_40_06v2.hdf5\n",
      "Epoch 4/10\n",
      "418/418 [==============================] - 146s 349ms/step - loss: 1.3356 - acc: 0.5907 - val_loss: 2.5602 - val_acc: 0.2129\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.19857 to 0.21291, saving model to ../checkpoints/epoch_10_03_19_2019_00_40_06v2.hdf5\n",
      "Epoch 5/10\n",
      "418/418 [==============================] - 152s 363ms/step - loss: 0.9250 - acc: 0.7247 - val_loss: 2.7240 - val_acc: 0.2114\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.21291\n",
      "Epoch 6/10\n",
      "418/418 [==============================] - 154s 368ms/step - loss: 0.6886 - acc: 0.8055 - val_loss: 2.9998 - val_acc: 0.1993\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.21291\n",
      "Epoch 7/10\n",
      "418/418 [==============================] - 156s 372ms/step - loss: 0.5447 - acc: 0.8497 - val_loss: 3.2142 - val_acc: 0.2023\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.21291\n",
      "Epoch 8/10\n",
      "418/418 [==============================] - 153s 367ms/step - loss: 0.4570 - acc: 0.8722 - val_loss: 3.1848 - val_acc: 0.2054\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.21291\n",
      "Epoch 9/10\n",
      "418/418 [==============================] - 150s 358ms/step - loss: 0.3990 - acc: 0.8911 - val_loss: 3.4215 - val_acc: 0.2023\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.21291\n",
      "Epoch 10/10\n",
      "418/418 [==============================] - 151s 362ms/step - loss: 0.3415 - acc: 0.9056 - val_loss: 3.7255 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.21291\n"
     ]
    }
   ],
   "source": [
    "def gen_filename_h5():\n",
    "    return 'epoch_'+str(epochs) + '_' + datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "\n",
    "\n",
    "def gen_filename_csv():\n",
    "    return 'epoch_'+str(epochs) + '_' + datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")\n",
    "\n",
    "\n",
    "# Checkpoint auto\n",
    "filepath = \"../checkpoints/\"+gen_filename_h5()+\"v2.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "steps_per_epoch = image_generator.samples//image_generator.batch_size\n",
    "valid_steps_per_epoch = valid_generator.samples // valid_generator.batch_size\n",
    "test_steps_per_epoch = test_generator.samples // test_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=image_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=valid_steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=[checkpointer],\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867/867 [==============================] - 392s 452ms/step\n",
      "(55440, 14)\n"
     ]
    }
   ],
   "source": [
    "def perform_test():\n",
    "    prediction_specialized = model.predict_generator(test_generator, verbose=1, steps=test_steps_per_epoch+1)\n",
    "    return prediction_specialized\n",
    "\n",
    "if gen_test:\n",
    "    prediction_specialized = perform_test()\n",
    "    predicted_label_specialized = [np.argmax(prediction_specialized[i]) for i in range(len(prediction_specialized))]\n",
    "    print(prediction_specialized.shape)\n",
    "    df = pd.DataFrame({'itemid': test_data_specialized['itemid'].astype(int), 'Category': predicted_label_specialized})\n",
    "    df.to_csv(path_or_buf='res' + gen_filename_csv() + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55440, 14)\n"
     ]
    }
   ],
   "source": [
    "print(prediction_specialized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
