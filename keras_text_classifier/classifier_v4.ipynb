{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'others mobile & tablet': 35, 'smartfren': 53, 'infinix': 40, 'brandcode': 39, 'icherry': 52, 'advan': 45, 'iphone': 31, 'realme': 51, 'motorola': 49, 'maxtron': 56, 'nokia': 38, 'xiaomi': 34, 'mito': 46, 'sony': 33, 'spc': 57, 'lenovo': 37, 'alcatel': 55, 'samsung': 32, 'vivo': 42, 'evercoss': 44, 'strawberry': 50, 'blackberry': 36, 'asus': 43, 'honor': 54, 'oppo': 41, 'huawei': 47, 'sharp': 48, 'wedding dress': 23, 'shirt': 27, 'casual dress': 18, 'maxi dress': 20, 'big size dress': 24, 'bodycon dress': 22, 'party dress': 19, 'blouse': 26, 'tshirt': 25, 'crop top': 29, 'tanktop': 28, 'others': 17, 'a line dress': 21, 'big size top': 30, 'foundation': 1, 'face palette': 0, 'concealer': 7, 'lip gloss': 14, 'blush on': 2, 'highlighter': 8, 'bb & cc cream': 5, 'other face cosmetics': 4, 'lip tint': 13, 'bronzer': 11, 'lip liner': 15, 'powder': 3, 'setting spray': 10, 'primer': 9, 'contour': 6, 'other lip cosmetics': 16, 'lipstick': 12}\n",
      "no of categories: 58\n",
      "custom train data used\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Conv1D, GlobalMaxPooling1D, Flatten, LSTM, \\\n",
    "    Bidirectional, MaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "import pandas as pd\n",
    "\n",
    "from utility.train_data_loader import load_train_data\n",
    "\n",
    "\n",
    "testData = pd.read_csv(\"../data/test.csv\")\n",
    "dictData = pd.read_csv(\"../data/kata_dasar_kbbi.csv\")\n",
    "categories_file = open(\"../data/categories.json\", \"r\")\n",
    "categories = json.load(categories_file)\n",
    "inverted_categories_mobile = {v: k.lower() for k, v in categories['Mobile'].items()}\n",
    "inverted_categories_fashion = {v: k.lower() for k, v in categories['Fashion'].items()}\n",
    "inverted_categories_beauty = {v: k.lower() for k, v in categories['Beauty'].items()}\n",
    "\n",
    "all_subcategories = {k.lower(): v for k, v in categories['Mobile'].items()}\n",
    "all_subcategories.update({k.lower(): v for k, v in categories['Fashion'].items()})\n",
    "all_subcategories.update({k.lower(): v for k, v in categories['Beauty'].items()})\n",
    "\n",
    "# Main settings\n",
    "plot_history_check = True\n",
    "gen_test = True\n",
    "max_length = 35  # 32 is max word in train\n",
    "max_words = 2500\n",
    "num_classes = len(all_subcategories)\n",
    "# Training for more epochs will likelval-acc after 10 epochs: 0.71306y lead to overfitting on this dataset\n",
    "# You can try tweaking these hyperparamaters when using this model with your own data\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "print(all_subcategories)\n",
    "print(\"no of categories: \" + str(num_classes))\n",
    "\n",
    "category_mapping = {\n",
    "    'fashion_image': 'Fashion',\n",
    "    'beauty_image': 'Beauty',\n",
    "    'mobile_image': 'Mobile',\n",
    "}\n",
    "directory_mapping = {\n",
    "    'Fashion': 'fashion_image',\n",
    "    'Beauty': 'beauty_image',\n",
    "    'Mobile': 'mobile_image',\n",
    "}\n",
    "\n",
    "trainData = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Category</th>\n",
       "      <th>image_path</th>\n",
       "      <th>item_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487927</th>\n",
       "      <td>723561441</td>\n",
       "      <td>atas wanita kemeja lengan panjang ij lg stripe...</td>\n",
       "      <td>27</td>\n",
       "      <td>fashion_image/7d53cdc75ba4ad2bccb682bf33701627...</td>\n",
       "      <td>shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410094</th>\n",
       "      <td>1718626886</td>\n",
       "      <td>best seller black lace sleeve dress pesta mini...</td>\n",
       "      <td>18</td>\n",
       "      <td>fashion_image/8e41b179b48a73d22db77934c0db800b...</td>\n",
       "      <td>casual dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86696</th>\n",
       "      <td>838724637</td>\n",
       "      <td>catrice hd liquid coverage foundation</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/bbae6b05a25f3753d3b45e81ebf80e34.jpg</td>\n",
       "      <td>foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293146</th>\n",
       "      <td>1660979197</td>\n",
       "      <td>dress bodycon mini sexy model off shoulder len...</td>\n",
       "      <td>21</td>\n",
       "      <td>fashion_image/9a4e2c84a93941c6bf21cf8ec9551bfe...</td>\n",
       "      <td>a line dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158120</th>\n",
       "      <td>504154458</td>\n",
       "      <td>cream glansie paket normal dr fajar</td>\n",
       "      <td>4</td>\n",
       "      <td>beauty_image/6f1942777ee11792996a4c410df73f4c.jpg</td>\n",
       "      <td>other face cosmetics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            itemid                                              title  \\\n",
       "487927   723561441  atas wanita kemeja lengan panjang ij lg stripe...   \n",
       "410094  1718626886  best seller black lace sleeve dress pesta mini...   \n",
       "86696    838724637              catrice hd liquid coverage foundation   \n",
       "293146  1660979197  dress bodycon mini sexy model off shoulder len...   \n",
       "158120   504154458                cream glansie paket normal dr fajar   \n",
       "\n",
       "        Category                                         image_path  \\\n",
       "487927        27  fashion_image/7d53cdc75ba4ad2bccb682bf33701627...   \n",
       "410094        18  fashion_image/8e41b179b48a73d22db77934c0db800b...   \n",
       "86696          1  beauty_image/bbae6b05a25f3753d3b45e81ebf80e34.jpg   \n",
       "293146        21  fashion_image/9a4e2c84a93941c6bf21cf8ec9551bfe...   \n",
       "158120         4  beauty_image/6f1942777ee11792996a4c410df73f4c.jpg   \n",
       "\n",
       "               item_category  \n",
       "487927                 shirt  \n",
       "410094          casual dress  \n",
       "86696             foundation  \n",
       "293146          a line dress  \n",
       "158120  other face cosmetics  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599953 666615\n",
      "599953 599953\n",
      "41558\n"
     ]
    }
   ],
   "source": [
    "# Shuffle train data\n",
    "trainData = shuffle(trainData)\n",
    "\n",
    "max_data_size = int(len(trainData) * 1)\n",
    "train_data_size = int(max_data_size * .9)\n",
    "train_data_step = 1\n",
    "validate_data_step = 1\n",
    "print(train_data_size, max_data_size)\n",
    "\n",
    "train_texts = trainData['title'][:train_data_size:train_data_step]\n",
    "valid_texts = trainData['title'][train_data_size::train_data_step]\n",
    "train_tags = trainData['Category'][:train_data_size:train_data_step]\n",
    "valid_tags = trainData['Category'][train_data_size::train_data_step]\n",
    "test_texts = testData['title']\n",
    "print(len(train_texts), len(train_tags))\n",
    "\n",
    "y = train_tags.values\n",
    "\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_texts)  # only fit on train\n",
    "x_train = tokenize.texts_to_sequences(train_texts)\n",
    "x_valid = tokenize.texts_to_sequences(valid_texts)\n",
    "x_test = tokenize.texts_to_sequences(test_texts)\n",
    "\n",
    "word_index = tokenize.word_index\n",
    "\n",
    "# Pad sequences with zeros\n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=max_length)\n",
    "x_valid = pad_sequences(x_valid,padding='post',maxlen=max_length)\n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=max_length)\n",
    "\n",
    "y_train = train_tags.values\n",
    "y_valid = valid_tags.values\n",
    "vocab_size = len(tokenize.word_index) + 1\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32,  51,  15, 213,  13, 322, 601,   4,  81,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainData['title'], trainData['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the target variable\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create a count vectorizer object\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainData['title'])\n",
    "print(\"\")\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainData['title'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainData['title'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainData['title'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x)\n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclassifier = xgboost.XGBClassifier(verbosity = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, Count Vectors:  0.6870942191606562\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(xgbclassifier, xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print (\"Xgb, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgb, WordLevel TF-IDF:  0.6889003564270885\n"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgbclassifier, xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print (\"Xgb, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(verbosity = 3), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print (\"Xgb, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
